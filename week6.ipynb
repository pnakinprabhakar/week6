{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Vpdzic54YrzVzixNk8C0Ls_AQ3K92D5b",
      "authorship_tag": "ABX9TyMYF64oeR3FFqTF0Zcad3yb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pnakinprabhakar/week6/blob/main/week6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task: File Ingestion and Schema validation\n",
        "Take any csv/text file of 2+ GB of your choice. --- (You can do this assignment on Google colab)\n",
        "\n",
        "Read the file ( Present approach of reading the file )\n",
        "\n",
        "Try different methods of file reading eg: Dask, Modin, Ray, pandas and present your findings in term of computational efficiency\n",
        "\n",
        "Perform basic validation on data columns : eg: remove special character , white spaces from the col name\n",
        "\n",
        "As you already know the schema hence create a YAML file and write the column name in YAML file. --define separator of\n",
        "read and write file, column name in YAML\n",
        "\n",
        "Validate number of columns and column name of ingested file with YAML.\n",
        "\n",
        "Write the file in pipe separated text file (|) in gz format.\n",
        "\n",
        "Create a summary of the file:\n",
        "\n",
        "Total number of rows,\n",
        "\n",
        "total number of columns\n",
        "\n",
        "file size"
      ],
      "metadata": {
        "id": "A32uJCrZbWRf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "sgHCHg_6E6-G"
      },
      "outputs": [],
      "source": [
        "import os \n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dask import dataframe as dd"
      ],
      "metadata": {
        "id": "UVnrAut8eBky"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "dask_df = dd.read_csv('/content/drive/MyDrive/data/week6/IMDB Top 250 Movies.csv')\n",
        "end = time.time()\n",
        "print('Read csv with dask = ',(end-start),'sec')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3umbxD0geN3u",
        "outputId": "605f115d-6acc-482f-9615-3012a282bc13"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Read csv with dask =  0.3543245792388916 sec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "start = time.time()\n",
        "df = pd.read_csv('/content/drive/MyDrive/data/week6/IMDB Top 250 Movies.csv')\n",
        "end = time.time()\n",
        "print(\"Read csv with Pandas\",(end-start),\"sec\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITNYqnHAevq7",
        "outputId": "7cf4228e-4b61-4f27-a5a1-ff7b1287f8b0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Read csv with Pandas 0.01314544677734375 sec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validation"
      ],
      "metadata": {
        "id": "-hvrIk1vfEdm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import os \n",
        "import subprocess\n",
        "import yaml\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import gc\n",
        "import re"
      ],
      "metadata": {
        "id": "iY7AP5OXfAm3"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile utility.py\n",
        "\n",
        "def read_config_file(filepath):\n",
        "    with open(filepath, 'r') as stream:\n",
        "        try:\n",
        "            return yaml.load(stream, Loader=yaml.Loader)\n",
        "        except yaml.YAMLError as exc:\n",
        "            logging.error(exc)\n",
        "\n",
        "def col_header_val(df,table_config):\n",
        "    df.columns = df.columns.str.lower()\n",
        "    df.columns = df.columns.str.replace('[^\\w]','_',regex=True)\n",
        "    df.columns = list(map(lambda x: x.strip('_'), list(df.columns)))\n",
        "    df.columns = list(map(lambda x: replacer(x,'_'), list(df.columns)))\n",
        "    expected_col = list(map(lambda x: x.lower(),  table_config['columns']))\n",
        "    expected_col.sort()\n",
        "    df.columns =list(map(lambda x: x.lower(), list(df.columns)))\n",
        "    df = df.reindex(sorted(df.columns), axis=1)\n",
        "    if len(df.columns) == len(expected_col) and list(expected_col)  == list(df.columns):\n",
        "        print(\"column name and column length validation passed\")\n",
        "        return 1\n",
        "    else:\n",
        "        print(\"column name and column length validation failed\")\n",
        "        mismatched_columns_file = list(set(df.columns).difference(expected_col))\n",
        "        print(\"Following File columns are not in the YAML file\",mismatched_columns_file)\n",
        "        missing_YAML_file = list(set(expected_col).difference(df.columns))\n",
        "        print(\"Following YAML columns are not in the file uploaded\",missing_YAML_file)\n",
        "        logging.info(f'df columns: {df.columns}')\n",
        "        logging.info(f'expected columns: {expected_col}')\n",
        "        return 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPs-Q6Rufofb",
        "outputId": "05c82fe0-a14e-4dcf-ab1f-a7d44060d464"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing utility.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YZdZ1R--gW8c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}